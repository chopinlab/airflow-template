from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.datasets import Dataset
import os
import json
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset as TorchDataset, DataLoader
from PIL import Image
import numpy as np
from sklearn.metrics import accuracy_score, classification_report
import mlflow
import mlflow.pytorch

# Dataset ì •ì˜
training_data_dataset = Dataset("file:///opt/airflow/data/train/")
model_dataset = Dataset("file:///opt/airflow/models/latest.pth")
inference_results_dataset = Dataset("file:///opt/airflow/data/inference_results.json")

default_args = {
    'owner': 'ml-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'image_classification_pipeline',
    default_args=default_args,
    description='Complete image classification pipeline - train and inference',
    schedule=timedelta(hours=6),
    catchup=False,
    tags=['pytorch', 'image-classification', 'computer-vision'],
)

class ImageDataset(TorchDataset):
    """ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_path, labels_dict, transform=None):
        self.data_path = data_path
        self.labels_dict = labels_dict
        self.transform = transform
        self.class_to_idx = {'cat': 0, 'dog': 1}
        
    def __len__(self):
        return len(self.labels_dict)
    
    def __getitem__(self, idx):
        filenames = list(self.labels_dict.keys())
        filename = filenames[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = os.path.join(self.data_path, filename)
        image = Image.open(img_path).convert('RGB')
        
        # í…ì„œë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì •ê·œí™”)
        image = np.array(image).astype(np.float32) / 255.0
        image = torch.from_numpy(image).permute(2, 0, 1)  # CHW í˜•ì‹ìœ¼ë¡œ
        
        # ë ˆì´ë¸”
        label_name = self.labels_dict[filename]
        label = self.class_to_idx[label_name]
        
        return image, label

class SimpleCNN(nn.Module):
    """ê°„ë‹¨í•œ CNN ëª¨ë¸ (CPU ìµœì í™”)"""
    
    def __init__(self, num_classes=2):
        super(SimpleCNN, self).__init__()
        
        # ì…ë ¥: 3x64x64
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  # 16x64x64
        self.pool1 = nn.MaxPool2d(2, 2)              # 16x32x32
        
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # 32x32x32  
        self.pool2 = nn.MaxPool2d(2, 2)              # 32x16x16
        
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) # 64x16x16
        self.pool3 = nn.MaxPool2d(2, 2)              # 64x8x8
        
        # Fully connected layers
        self.fc1 = nn.Linear(64 * 8 * 8, 128)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, num_classes)
        
    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        x = self.pool3(F.relu(self.conv3(x)))
        
        x = x.view(-1, 64 * 8 * 8)  # Flatten
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        
        return x

def generate_sample_data(**context):
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    import subprocess
    
    print("ğŸ¨ Generating sample images...")
    result = subprocess.run([
        'python', '/opt/airflow/data/generate_sample_data.py'
    ], capture_output=True, text=True, cwd='/opt/airflow')
    
    if result.returncode == 0:
        print("âœ… Sample data generated successfully")
        print(result.stdout)
    else:
        print("âŒ Error generating sample data")
        print(result.stderr)
        raise Exception(f"Data generation failed: {result.stderr}")
    
    return "data_generated"

def train_model(**context):
    """PyTorch ëª¨ë¸ í›ˆë ¨"""
    print("ğŸš€ Starting model training...")
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("image_classification")
    
    with mlflow.start_run(run_name=f"training_{context['ds']}") as run:
        
        # ë ˆì´ë¸” íŒŒì¼ ë¡œë“œ
        with open('/opt/airflow/data/labels.json', 'r') as f:
            labels = json.load(f)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = ImageDataset(
            '/opt/airflow/data/train/images',
            labels['train']
        )
        
        val_dataset = ImageDataset(
            '/opt/airflow/data/val/images', 
            labels['val']
        )
        
        # ë°ì´í„° ë¡œë”
        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = SimpleCNN(num_classes=2)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params({
            'batch_size': 4,
            'learning_rate': 0.001,
            'epochs': 10,
            'model_type': 'SimpleCNN',
            'optimizer': 'Adam'
        })
        
        print(f"ğŸ“Š Training data: {len(train_dataset)} samples")
        print(f"ğŸ“Š Validation data: {len(val_dataset)} samples")
        
        # í›ˆë ¨ ë£¨í”„
        model.train()
        for epoch in range(10):  # CPUì—ì„œ ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ 10 ì—í¬í¬
            running_loss = 0.0
            correct_predictions = 0
            total_predictions = 0
            
            for batch_idx, (images, labels_batch) in enumerate(train_loader):
                optimizer.zero_grad()
                
                outputs = model(images)
                loss = criterion(outputs, labels_batch)
                loss.backward()
                optimizer.step()
                
                running_loss += loss.item()
                
                # ì •í™•ë„ ê³„ì‚°
                _, predicted = torch.max(outputs.data, 1)
                total_predictions += labels_batch.size(0)
                correct_predictions += (predicted == labels_batch).sum().item()
            
            # ì—í¬í¬ë³„ ê²°ê³¼
            epoch_loss = running_loss / len(train_loader)
            epoch_acc = correct_predictions / total_predictions
            
            print(f"Epoch {epoch+1}/10 - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}")
            
            # MLflow ë¡œê¹…
            mlflow.log_metrics({
                'train_loss': epoch_loss,
                'train_accuracy': epoch_acc
            }, step=epoch)
        
        # ê²€ì¦
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for images, labels_batch in val_loader:
                outputs = model(images)
                loss = criterion(outputs, labels_batch)
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs, 1)
                val_total += labels_batch.size(0)
                val_correct += (predicted == labels_batch).sum().item()
        
        val_accuracy = val_correct / val_total
        val_loss = val_loss / len(val_loader)
        
        print(f"ğŸ¯ Validation Results - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}")
        
        # ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metrics({
            'val_loss': val_loss,
            'val_accuracy': val_accuracy,
            'total_params': sum(p.numel() for p in model.parameters())
        })
        
        # ëª¨ë¸ ì €ì¥ (.pth íŒŒì¼)
        model_path = '/opt/airflow/models/image_classifier.pth'
        os.makedirs('/opt/airflow/models', exist_ok=True)
        
        torch.save({
            'model_state_dict': model.state_dict(),
            'model_class': 'SimpleCNN',
            'num_classes': 2,
            'class_to_idx': {'cat': 0, 'dog': 1},
            'val_accuracy': val_accuracy,
            'epoch': 10
        }, model_path)
        
        print(f"ğŸ’¾ Model saved to: {model_path}")
        
        # MLflowì—ë„ ëª¨ë¸ ë“±ë¡
        mlflow.pytorch.log_model(
            model, 
            "model",
            registered_model_name="ImageClassifier"
        )
        
        # XComì— ê²°ê³¼ ì €ì¥
        context['ti'].xcom_push(key='model_path', value=model_path)
        context['ti'].xcom_push(key='val_accuracy', value=val_accuracy)
        context['ti'].xcom_push(key='run_id', value=run.info.run_id)
        
        return {
            'model_path': model_path,
            'val_accuracy': val_accuracy,
            'run_id': run.info.run_id
        }

def run_inference(**context):
    """í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰"""
    print("ğŸ”® Running inference...")
    
    # í›ˆë ¨ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    model_path = context['ti'].xcom_pull(task_ids='train_model', key='model_path')
    
    if not model_path or not os.path.exists(model_path):
        raise Exception("Trained model not found!")
    
    # ë ˆì´ë¸” íŒŒì¼ ë¡œë“œ
    with open('/opt/airflow/data/labels.json', 'r') as f:
        labels = json.load(f)
    
    # ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location='cpu')
    model = SimpleCNN(num_classes=2)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    idx_to_class = {0: 'cat', 1: 'dog'}
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¶”ë¡ 
    test_dataset = ImageDataset(
        '/opt/airflow/data/test/images',
        labels['test']
    )
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
    
    predictions = []
    ground_truths = []
    
    print("ğŸ¯ Running inference on test data...")
    
    with torch.no_grad():
        for images, true_labels in test_loader:
            outputs = model(images)
            probabilities = F.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, 1)
            
            pred_class = idx_to_class[predicted.item()]
            true_class = idx_to_class[true_labels.item()]
            confidence = probabilities[0][predicted].item()
            
            result = {
                'predicted_class': pred_class,
                'true_class': true_class,
                'confidence': confidence,
                'correct': pred_class == true_class
            }
            
            predictions.append(result)
            ground_truths.append(true_class == pred_class)
            
            print(f"  Predicted: {pred_class} (confidence: {confidence:.3f}) | True: {true_class} | âœ…" if result['correct'] else f"  Predicted: {pred_class} (confidence: {confidence:.3f}) | True: {true_class} | âŒ")
    
    # ì „ì²´ ì •í™•ë„ ê³„ì‚°
    test_accuracy = sum(ground_truths) / len(ground_truths)
    
    # ê²°ê³¼ ì €ì¥
    inference_results = {
        'test_accuracy': test_accuracy,
        'total_samples': len(predictions),
        'correct_predictions': sum(ground_truths),
        'timestamp': context['ds'],
        'model_path': model_path,
        'predictions': predictions
    }
    
    results_path = '/opt/airflow/data/inference_results.json'
    with open(results_path, 'w') as f:
        json.dump(inference_results, f, indent=2)
    
    print(f"ğŸ“Š Test Accuracy: {test_accuracy:.4f}")
    print(f"ğŸ“ Results saved to: {results_path}")
    
    # MLflowì— ì¶”ë¡  ê²°ê³¼ ë¡œê¹…
    mlflow.set_tracking_uri("http://mlflow:5000")
    with mlflow.start_run(run_name=f"inference_{context['ds']}"):
        mlflow.log_metrics({
            'test_accuracy': test_accuracy,
            'total_samples': len(predictions),
            'correct_predictions': sum(ground_truths)
        })
        mlflow.log_artifact(results_path)
    
    context['ti'].xcom_push(key='test_accuracy', value=test_accuracy)
    context['ti'].xcom_push(key='results_path', value=results_path)
    
    return inference_results

def evaluate_model_performance(**context):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ë³´ê³ ì„œ ìƒì„±"""
    print("ğŸ“ˆ Evaluating model performance...")
    
    val_accuracy = context['ti'].xcom_pull(task_ids='train_model', key='val_accuracy')
    test_accuracy = context['ti'].xcom_pull(task_ids='run_inference', key='test_accuracy')
    
    print("\n" + "="*50)
    print("ğŸ¯ MODEL PERFORMANCE REPORT")
    print("="*50)
    print(f"ğŸ“Š Validation Accuracy: {val_accuracy:.4f}")
    print(f"ğŸ¯ Test Accuracy: {test_accuracy:.4f}")
    print(f"ğŸ“‰ Generalization Gap: {abs(val_accuracy - test_accuracy):.4f}")
    
    # ì„±ëŠ¥ í‰ê°€
    if test_accuracy > 0.8:
        status = "ğŸ‰ EXCELLENT"
    elif test_accuracy > 0.6:
        status = "ğŸ‘ GOOD"
    else:
        status = "âš ï¸  NEEDS IMPROVEMENT"
    
    print(f"ğŸ† Overall Performance: {status}")
    print("="*50)
    
    # ëª¨ë¸ ìŠ¹ê²© ê²°ì •
    if test_accuracy > 0.7:
        promotion_decision = "promote_to_production"
        print("âœ… Model ready for production deployment")
    else:
        promotion_decision = "retrain_needed"
        print("ğŸ”„ Model needs retraining before deployment")
    
    return {
        'val_accuracy': val_accuracy,
        'test_accuracy': test_accuracy,
        'promotion_decision': promotion_decision,
        'performance_status': status
    }

# Task ì •ì˜
generate_data_task = PythonOperator(
    task_id='generate_sample_data',
    python_callable=generate_sample_data,
    dag=dag,
    outlets=[training_data_dataset]
)

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag,
    outlets=[model_dataset]
)

inference_task = PythonOperator(
    task_id='run_inference', 
    python_callable=run_inference,
    dag=dag,
    outlets=[inference_results_dataset]
)

evaluate_task = PythonOperator(
    task_id='evaluate_performance',
    python_callable=evaluate_model_performance,
    dag=dag
)

# Task ì˜ì¡´ì„±
generate_data_task >> train_task >> inference_task >> evaluate_task