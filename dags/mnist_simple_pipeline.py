from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.datasets import Dataset
import subprocess
import logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# Dataset ì •ì˜
mnist_data_dataset = Dataset("mlflow://mnist-data")
mnist_model_dataset = Dataset("mlflow://models/MNIST-CNN/latest")

default_args = {
    'owner': 'ml-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'mnist_simple_pipeline',
    default_args=default_args,
    description='MNIST ì†ê¸€ì”¨ ìˆ«ì ë¶„ë¥˜ ML íŒŒì´í”„ë¼ì¸ (ë‹¨ìˆœí™” ë²„ì „)',
    schedule=timedelta(hours=12),
    catchup=False,
    tags=['mnist', 'pytorch', 'classification', 'simple'],
)

def trigger_mnist_training(**context):
    """MLflow ì„œë²„ì—ì„œ MNIST ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰"""
    try:
        logger.info("ğŸš€ Starting MNIST model training in mlflow-server...")
        
        # í›ˆë ¨ íŒŒë¼ë¯¸í„° (ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ ë°ì´í„° ì œí•œ)
        training_params = {
            "epochs": "2",
            "batch_size": "128", 
            "lr": "1.0",
            "gamma": "0.7",
            "seed": "42",
            "data_limit": "5000"  # 5000ê°œ ìƒ˜í”Œë§Œ ì‚¬ìš© (ë¹ ë¥¸ í›ˆë ¨)
        }
        
        # mlflow-server ì»¨í…Œì´ë„ˆì—ì„œ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰
        cmd = [
            "docker", "exec", "airflow-template_mlflow-server_1",
            "python", "/mlflow-projects/mnist-classification/train.py",
            "--epochs", training_params["epochs"],
            "--batch-size", training_params["batch_size"],
            "--lr", training_params["lr"],
            "--gamma", training_params["gamma"],
            "--seed", training_params["seed"],
            "--data-limit", training_params["data_limit"],
            "--model-dir", "/mlflow-projects/mnist-classification/models"
        ]
        
        logger.info(f"ğŸ”§ Executing command: {' '.join(cmd)}")
        
        # í›ˆë ¨ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ 10ë¶„ìœ¼ë¡œ ì¦ê°€)
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
        
        if result.returncode == 0:
            logger.info("âœ… MNIST training completed successfully!")
            logger.info(f"Training output: {result.stdout}")
            
            # ì„±ê³µ ì •ë³´ë¥¼ XComì— ì €ì¥
            context['ti'].xcom_push(key='training_status', value='success')
            context['ti'].xcom_push(key='training_output', value=result.stdout)
            
            return "MNIST training completed successfully"
        else:
            # ì—ëŸ¬ ë¡œê·¸ì—ì„œ í›ˆë ¨ ì„±ê³µ ì—¬ë¶€ í™•ì¸ (MLflow ì—ëŸ¬ vs ì‹¤ì œ í›ˆë ¨ ì—ëŸ¬)
            stderr_output = result.stderr
            if "ğŸ¯ Training completed!" in stderr_output and "Best test accuracy:" in stderr_output:
                logger.warning("âš ï¸  Training succeeded but MLflow artifact logging failed")
                logger.info("âœ… Model was saved locally, continuing pipeline...")
                
                # ë¶€ë¶„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                context['ti'].xcom_push(key='training_status', value='success')
                context['ti'].xcom_push(key='training_output', value=stderr_output)
                
                return "MNIST training completed (with MLflow artifact warning)"
            else:
                logger.error(f"âŒ Training failed: {stderr_output}")
                raise Exception(f"MNIST training failed: {stderr_output}")
        
    except Exception as e:
        logger.error(f"âŒ MNIST training failed: {str(e)}")
        context['ti'].xcom_push(key='training_status', value='failed')
        raise Exception(f"MNIST training failed: {str(e)}")

def trigger_mnist_inference(**context):
    """MLflow ì„œë²„ì—ì„œ MNIST ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
    try:
        # ì´ì „ í›ˆë ¨ ìƒíƒœ í™•ì¸
        training_status = context['ti'].xcom_pull(task_ids='run_training', key='training_status')
        logger.info(f"ğŸ“Š Retrieved training status: {training_status}")
        
        if training_status != 'success':
            logger.warning(f"âš ï¸  Training status is '{training_status}', but attempting inference anyway...")
            # í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´ ì¶”ë¡ ì„ ê³„ì† ì§„í–‰
        else:
            logger.info("âœ… Training was successful, proceeding with inference")
        
        logger.info("ğŸ” Starting MNIST model inference in mlflow-server...")
        
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš© (MLflowì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ ë¡œì»¬ íŒŒì¼ ì‚¬ìš©)
        model_uri = "models:/MNIST-CNN/latest"  # MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìµœì‹  ë²„ì „ ì‚¬ìš©
        
        # mlflow-server ì»¨í…Œì´ë„ˆì—ì„œ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰
        cmd = [
            "docker", "exec", "airflow-template_mlflow-server_1",
            "python", "/mlflow-projects/mnist-classification/inference.py",
            "--model-uri", model_uri,
            "--output-dir", "/mlflow-projects/mnist-classification/inference_results"
        ]
        
        logger.info(f"ğŸ”§ Executing command: {' '.join(cmd)}")
        
        # ì¶”ë¡  ì‹¤í–‰
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)
        
        if result.returncode == 0:
            logger.info("âœ… MNIST inference completed successfully!")
            logger.info(f"Inference output: {result.stdout}")
            
            context['ti'].xcom_push(key='inference_status', value='success')
            context['ti'].xcom_push(key='inference_output', value=result.stdout)
            
            return "MNIST inference completed successfully"
        else:
            logger.error(f"âŒ Inference failed: {result.stderr}")
            raise Exception(f"MNIST inference failed: {result.stderr}")
        
    except Exception as e:
        logger.error(f"âŒ MNIST inference failed: {str(e)}")
        context['ti'].xcom_push(key='inference_status', value='failed')
        raise Exception(f"MNIST inference failed: {str(e)}")

def validate_pipeline(**context):
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ê²€ì¦"""
    try:
        logger.info("âœ… Validating pipeline results...")
        
        training_status = context['ti'].xcom_pull(key='training_status')
        inference_status = context['ti'].xcom_pull(key='inference_status')
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ MNIST SIMPLE PIPELINE VALIDATION REPORT")
        logger.info("="*60)
        logger.info(f"ğŸš‚ Training Status: {'âœ… SUCCESS' if training_status == 'success' else 'âŒ FAILED'}")
        logger.info(f"ğŸ”® Inference Status: {'âœ… SUCCESS' if inference_status == 'success' else 'âŒ FAILED'}")
        logger.info(f"ğŸ  Execution Environment: mlflow-server container")
        logger.info(f"ğŸ”— Architecture: Simple direct execution")
        logger.info("="*60)
        
        pipeline_success = training_status == 'success' and inference_status == 'success'
        
        if pipeline_success:
            logger.info("ğŸ‰ MNIST Simple Pipeline: âœ… SUCCESS")
            logger.info("ğŸš€ All tasks completed in mlflow-server!")
        else:
            logger.info("âš ï¸ MNIST Simple Pipeline: âŒ ISSUES FOUND")
        
        logger.info("="*60 + "\n")
        
        return {
            'training_completed': training_status == 'success',
            'inference_completed': inference_status == 'success',
            'pipeline_success': pipeline_success,
            'execution_environment': 'mlflow-server'
        }
        
    except Exception as e:
        logger.error(f"âŒ Pipeline validation failed: {str(e)}")
        raise Exception(f"Pipeline validation failed: {str(e)}")

# Task ì •ì˜
train_task = PythonOperator(
    task_id='train_model',
    python_callable=trigger_mnist_training,
    outlets=[mnist_model_dataset],
    dag=dag,
)

inference_task = PythonOperator(
    task_id='run_inference',
    python_callable=trigger_mnist_inference,
    dag=dag,
)

validate_task = PythonOperator(
    task_id='validate_pipeline',
    python_callable=validate_pipeline,
    dag=dag,
)

# ì„±ê³µ ë©”ì‹œì§€
success_message = BashOperator(
    task_id='success_notification',
    bash_command='''echo "
ğŸ‰ MNIST Simple Pipeline Completed Successfully! ğŸ‰

ğŸ“Š Pipeline Summary:
   - Training and inference executed in mlflow-server
   - No separate training container needed
   - Simple docker exec approach
   - Clean environment separation maintained

ğŸ—ï¸ Architecture Benefits:
   - âœ… Simplified container setup
   - âœ… Direct execution in ML environment
   - âœ… No complex API layers
   - âœ… Easy to scale (add more mlflow-server instances)

ğŸ” To view results:
   - MLflow UI: http://localhost:5000

ğŸš€ This approach is much simpler and more maintainable!
"''',
    dag=dag,
)

# Task ì˜ì¡´ì„±
train_task >> inference_task >> validate_task >> success_message