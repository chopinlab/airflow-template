services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
      POSTGRES_MULTIPLE_DATABASES: mlflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./scripts/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  mlflow-server:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://mlflow:mlflow@postgres:5432/mlflow
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - ./artifacts:/mlflow/artifacts
      - ./mlflow:/mlflow/data
    command: >
      bash -c "
        pip install mlflow psycopg2-binary &&
        sleep 10 &&
        mlflow server --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow --default-artifact-root /mlflow/artifacts --host 0.0.0.0 --port 5000
      "
    depends_on:
      postgres:
        condition: service_healthy
    restart: always

  mlflow-training:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    image: mlflow-pytorch:latest
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    volumes:
      - ./mlflow-projects:/mlflow-projects
      - ./data:/data
      - ./artifacts:/mlflow/artifacts
      - ./models:/models
    working_dir: /mlflow-projects/image-classification
    command: >
      bash -c "
        sleep 10 &&
        python training_api.py
      "
    ports:
      - "8000:8000"
    depends_on:
      mlflow-server:
        condition: service_started
    restart: always

  airflow:
    image: apache/airflow:3.0.4-python3.12
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__FERNET_KEY=ZmDfcTF7_60GrrY167zsiPd67pEvs0aGOv2oasOM1Pg=
      - _PIP_ADDITIONAL_REQUIREMENTS=mlflow>=2.8.0 requests>=2.28.0 bentoml
      - AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_USERS=admin:admin,mlops:user,viewer:viewer
      - AIRFLOW__CORE__SIMPLE_AUTH_MANAGER_ALL_ADMINS=True
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - AIRFLOW_CONN_MLFLOW_DEFAULT=http://mlflow-server:5000
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgres://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./models:/opt/airflow/models
      - ./data:/opt/airflow/data
      - ./notebooks:/opt/airflow/notebooks
      - ./configs:/opt/airflow/config
      - ./artifacts:/opt/airflow/artifacts
      - ./scripts:/opt/airflow/scripts
      - ./sql:/opt/airflow/sql
      - ./pyproject.toml:/tmp/pyproject.toml
    user: "${AIRFLOW_UID:-50000}:0"
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      mlflow-server:
        condition: service_started
    command: >
      bash -c "
        pip install mlflow requests airflow-provider-mlflow &&
        airflow db migrate &&
        python /opt/airflow/scripts/init-connections.py &&
        airflow standalone
      "
    restart: always

volumes:
  postgres-db-volume: